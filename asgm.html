<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li:not(:nth-child(1)) > a, .site-nav > ul.nav-list:first-child > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(1) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(1) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(1) > ul.nav-list { display: block; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>AutoSGM: Unifying Momentum Methods for Better Learning | Research Notes</title> <meta name="generator" content="Jekyll v4.4.1" /> <meta property="og:title" content="AutoSGM: Unifying Momentum Methods for Better Learning" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="AutoSGM Connecting the dots ‚Ä¶ HB, NAG, Adam." /> <meta property="og:description" content="AutoSGM Connecting the dots ‚Ä¶ HB, NAG, Adam." /> <link rel="canonical" href="http://localhost:4000/asgm.html" /> <meta property="og:url" content="http://localhost:4000/asgm.html" /> <meta property="og:site_name" content="Research Notes" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-09-11T00:00:00-07:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="AutoSGM: Unifying Momentum Methods for Better Learning" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-09-11T00:00:00-07:00","datePublished":"2025-09-11T00:00:00-07:00","description":"AutoSGM Connecting the dots ‚Ä¶ HB, NAG, Adam.","headline":"AutoSGM: Unifying Momentum Methods for Better Learning","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/asgm.html"},"url":"http://localhost:4000/asgm.html"}</script> <!-- End Jekyll SEO tag --> <script> window.MathJax = { tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, tags: 'ams' // Enables equation numbering if you use \label{} and \ref{} }, options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] } }; </script> <!--Macros--> <div style="display: none"> $$ \newcommand{sca}[1]{\langle #1 \rangle} \newcommand{\scalong}[1]{(#1_1,\dots,#1_k)} \newcommand{\red}[1]{\textcolor{OrangeRed}{#1}} \newcommand{\blue}[1]{\textcolor{blue}{#1}} \newcommand{\green}[1]{\textcolor{OliveGreen}{#1}} \newcommand{\orange}[1]{\textcolor{orange}{#1}} \newcommand{\purple}[1]{\textcolor{purple}{#1}} \newcommand{\gray}[1]{\textcolor{gray}{#1}} \newcommand{\teal}[1]{\textcolor{teal}{#1}} \newcommand{\gold}[1]{\textcolor{gold}{#1}} \newcommand{\bluea}[1]{\textcolor{RoyalBlue}{#1}} \newcommand{\reda}[1]{\textcolor{Red}{#1}} \newcommand{\redb}[1]{\textcolor{RubineRed}{#1}} \newcommand{\greena}[1]{\textcolor{LimeGreen}{#1}} \newcommand{\golden}[1]{\textcolor{GoldenRod}{#1}} \newcommand{\filter}[1]{\green{#1}} \newcommand{\param}[1]{\purple{#1}} \newcommand{\state}[1]{\blue{#1}} \newcommand{\statex}[1]{\bluea{#1}} \newcommand{\stateu}[1]{\greena{#1}} \newcommand{\statez}[1]{\golden{#1}} \newcommand{\input}[1]{\gray{#1}} \newcommand{\gain}[1]{\red{#1}} \newcommand{\gainx}[1]{\reda{#1}} \newcommand{\trust}[1]{\teal{#1}} \newcommand{\schedule}[1]{\gold{#1}} $$ </div> <!-- Load Google Fonts --> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <!-- Copied from https://docs.mathjax.org/en/latest/web/components/combined.html --> <script type="text/javascript" id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"> </script> <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> </script> <!-- Automatically display code inside script tags with type=math/tex using MathJax --> <!-- <script type="text/javascript" defer src="/assets/js/mathjax-script-type.js"> </script> --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"><div class="site-branding"> <span class="site-title ">Research Notes</span> <span class="site-description">Signal processing, and control in learning and optimization.</span> </div> </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in AutoSGM: Unifying Momentum Methods for Better Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/asgm.html" class="nav-list-link">AutoSGM: Unifying Momentum Methods for Better Learning</a><ul class="nav-list"><li class="nav-list-item"><a href="/learning_dynamics" class="nav-list-link">Learning Dynamics</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Learning-Rate Annealing as Controlled First-Order Dynamic Systems category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/lrwinds.html" class="nav-list-link">Learning-Rate Annealing as Controlled First-Order Dynamic Systems</a><ul class="nav-list"><li class="nav-list-item"><a href="/summary" class="nav-list-link">Summary</a></li></ul></li><li class="nav-list-item"><a href="/about" class="nav-list-link">About Me</a></li></ul> </nav> <footer class="site-footer"> ¬© 2025. <a href="/about">Oluwasegun Somefun</a> </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Research Notes" aria-label="Search Research Notes" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1 class="fs-9" id="autosgm"> <a href="#autosgm" class="anchor-heading" aria-labelledby="autosgm"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> AutoSGM </h1> <p class="fs-6 fw-300">Connecting the dots ‚Ä¶ HB, NAG, Adam.</p> <div class="d-flex mt-2"> <p class="text-small text-grey-dk-000 mb-0 mr-2">Page created: Sep 11 2025 at 12:00 AM</p> </div><hr /> <details> <summary class="text-delta"> Table of contents </summary> <ol id="markdown-toc"> <li><a href="#autosgm" id="markdown-toc-autosgm">AutoSGM</a> <ol> <li><a href="#-the-core-update-rule" id="markdown-toc--the-core-update-rule">üåÄ The Core Update Rule</a></li> <li><a href="#-an-optimal-learning-rate" id="markdown-toc--an-optimal-learning-rate">üìê An Optimal Learning Rate</a> <ol> <li><a href="#practical-approximation" id="markdown-toc-practical-approximation">Practical Approximation</a> <ol> <li><a href="#ema-realizations" id="markdown-toc-ema-realizations">EMA Realizations</a></li> </ol> </li> <li><a href="#robust-ema-estimation" id="markdown-toc-robust-ema-estimation">Robust EMA estimation</a> <ol> <li><a href="#1-input-clipping" id="markdown-toc-1-input-clipping">1. Input Clipping</a></li> <li><a href="#2-output-clipping-and-max-normalization" id="markdown-toc-2-output-clipping-and-max-normalization">2. Output Clipping and Max-Normalization</a></li> <li><a href="#3-layer-wise-smoothing" id="markdown-toc-3-layer-wise-smoothing">3. Layer-wise smoothing</a></li> </ol> </li> </ol> </li> <li><a href="#-unifying-phb-nag-and-adam" id="markdown-toc--unifying-phb-nag-and-adam">üß© Unifying PHB, NAG, and Adam</a></li> <li><a href="#-lowpass-regularization" id="markdown-toc--lowpass-regularization">üéØ Lowpass Regularization</a></li> <li><a href="#-key-empirical-findings" id="markdown-toc--key-empirical-findings">üìä Key Empirical Findings</a> <ol> <li><a href="#1-gpt-2-on-shakespeare-char-32-lower-test-loss-over-fixed-numerator-baseline" id="markdown-toc-1-gpt-2-on-shakespeare-char-32-lower-test-loss-over-fixed-numerator-baseline">1. GPT-2 on Shakespeare-char: <strong>~32% lower test loss</strong> over fixed-numerator baseline.</a></li> <li><a href="#2-vit-on-cifar10" id="markdown-toc-2-vit-on-cifar10">2. VIT on CIFAR10.</a></li> <li><a href="#3-resnet18-on-cifar10" id="markdown-toc-3-resnet18-on-cifar10">3. ResNet18 on CIFAR10.</a></li> <li><a href="#4-gpt-2-on-wikitext-103" id="markdown-toc-4-gpt-2-on-wikitext-103">4. GPT-2 on WikiText-103.</a></li> </ol> </li> <li><a href="#-conclusion" id="markdown-toc--conclusion">üèÅ Conclusion</a></li> </ol> </li> </ol> </details><hr /> <p>Momentum-based stochastic gradient methods such as <strong>Polyak‚Äôs Heavy Ball (PHB)</strong>, <strong>Nesterov‚Äôs Accelerated Gradient (NAG)</strong>, and <strong>Adam</strong> dominate deep learning optimization.</p> <p>They are often treated as separate algorithms, but in our recent work, we show they are all <strong>special cases</strong> of a single signal-processing (DSP) structure. The framework that allows us to do this is called the <strong>Automatic Stochastic Gradient Method (AutoSGM)</strong> framework.</p> <p>AutoSGM reframes these stochastic gradient optimizers through the lens of a <strong>first-order lowpass filter</strong> applied to the stochastic gradient, and the existence of an optimal iteration-dependent learning rate choice. The AutoSGM framework reveals:</p> <ul> <li>the <strong>first-order filtering mechanics</strong> behind what has been called <em>momentum</em>.</li> <li>that we can derive an <strong>optimal, iteration-dependent learning rate</strong> choice that involves <em>moment estimation</em>.</li> <li>that the smoothing effect of the first-order filter is a <strong>lowpass regularization</strong> of the loss surface.</li> </ul> <blockquote> <p><em>All algebraic operations are sample-by-sample (<strong>elementwise</strong>) unless otherwise stated.</em> The shorthand notation \((t,i)\) denotes the \(i\)-th element of a vector at iteration \(t\).</p> </blockquote><hr /> <h2 id="-the-core-update-rule"> <a href="#-the-core-update-rule" class="anchor-heading" aria-labelledby="-the-core-update-rule"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> üåÄ The Core Update Rule </h2> <p>The classic stochastic gradient method (SGM) updates parameters as:</p> \[\mathbf{w}(t+1,i) = \mathbf{w}(t,i) - \alpha(t,i) \, \mathbf{g}(t,i)\] <p>where:</p> <ul> <li>\(\mathbf{g}(t,i) = \nabla f(\mathbf{w}(t,i))\) is an unbiased stochastic gradient component,</li> <li>\(\alpha(t,i)\) denotes the learning rate at iteration \(t\), determined via a selected oracle function.</li> </ul> <p>In <strong>AutoSGM</strong>, we replace the stochastic gradient with a <strong>smoothed</strong> version:</p> \[\mathbf{w}(t+1,i) = \mathbf{w}(t,i) - \alpha(t,i) \, H_{\beta,\gamma}(\mathbf{g}(t,i))\] <p>Here, \(H_{\beta,\gamma}\) is a <strong>first-order filter</strong> with transfer function:</p> \[H(z) = \eta \, \frac{1 - \gamma z^{-1}}{1 - \beta z^{-1}}, \quad 0 \le \beta &lt; 1, \ \gamma &lt; \beta\] <p>The time (iteration)-domain realization is:</p> \[\mathbf{v}(t,i) = \beta\,\mathbf{v}(t-1,i) + \eta\,(\mathbf{g}(t,i) - \gamma\,\mathbf{g}(t-1,i))\] <p><strong>See this page for</strong> the <a href="/learning_dynamics">learning dynamics</a> of the stochastic gradient update in this framework.</p> <p>An <strong>interactive</strong> analysis of AutoSGM, using an extremely simple problem setup, can be found here <a href="/asgm_qsim" target="_blank">asgm_qsim</a>. This allows us to clarify that what is called <em>momentum</em> is better viewed as a first-order smoothing filter‚úÖ, and in particular derive Nesterov‚Äôs Accelerated Gradient (NAG) from first principles as <strong>a point in the filter design space</strong> where we set \(\gamma=\tfrac{\beta}{1+\beta}\).</p><hr /> <h2 id="-an-optimal-learning-rate"> <a href="#-an-optimal-learning-rate" class="anchor-heading" aria-labelledby="-an-optimal-learning-rate"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> üìê An Optimal Learning Rate </h2> <p>Assuming that both the training objective function and its gradient are Lipschitz continuous <a class="citation" href="#bottouOptimizationMethodsLargescale2018">(Bottou et al., 2018)</a>, and that the objective function admits an underlying log-likelihood interpretation.</p> <p>To derive an optimal learning rate, let \(\mathbb{E}\) denote expectation with respect to a model distribution \(p(\mathbf{w})\) parameterized by \(\mathbf{w}\). For an explicitly defined log-likelihood objective \(f=\ln p(\mathbf{w})\), the <strong>score-function</strong> identity, tells us that the expected gradient is zero for all \(\mathbf{w}\), not only at the optimum <a class="citation" href="#moonMathematicalMethodsAlgorithms2000">(Moon &amp; Stirling, 2000; Van Trees et al., 2013)</a>. Formally, \(\mathbb{E}[\mathbf{g}(t,i)] = 0\).</p> <blockquote> <p>In practice, many widely used training objectives admit log‚Äëlikelihood interpretations but differ from this simplified model.</p> </blockquote> <p>Using this model, define \(\mathbf{e}(t,i) = \mathbf{w}(t,i) - {\mathbf{w}(i)}^\star\) as the parameter error, the gap between current weight and a local optimum. Minimizing the expected squared error \(\mathbb{E}[\mathbf{e}(t+1,i)^2]\), at iteration \(t\), yields a closed-form expression for an <strong>iteration-dependent optimal learning rate</strong></p> \[\alpha(t,i)^\star = \frac{\mathbb{E}[\mathbf{w}(t,i) \,\mathbf{g}(t,i)]}{\mathbb{E}[\mathbf{g}(t,i)^2]},\] <p>This learning rate is the ratio of two expectation functions:</p> <ul> <li>numerator term is the <strong>partial-correlation</strong> between the weight and gradient.</li> <li>denominator term is the <strong>second moment</strong> (variance) of the gradient.</li> </ul> <p>This learning rate choice is locally-optimal at each iteration. In general, for our actual training objective functions, these expectations are unknown. Nevertheless, the learning rate can be realized in practice by iteratively approximating the expectations in the numerator and denominator terms.</p><hr /> <h3 id="practical-approximation"> <a href="#practical-approximation" class="anchor-heading" aria-labelledby="practical-approximation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Practical Approximation </h3> <p>The derived optimal learning‚Äërate function can be realized using standard adaptive‚Äëfiltering techniques <a class="citation" href="#dinizAdaptiveFilteringAlgorithms2020">(Diniz, 2020; Haykin, 2014)</a>, which involve the following steps:</p> <ol> <li>Expectations are estimated with <strong>exponential moving averages (EMA)</strong>.</li> <li>For numerical stability, we use the <strong>normalized gradient</strong> form.</li> <li>As a safety margin, the locally-optimal iteration-dependent learning rate estimate is modulated with a small \(\mu\digamma(t)\) which acts as its trust-region variable.</li> </ol> <p>Let \(0 \le \mu\digamma(t) \le 1\), where \(\mu &gt; 0\), \(0\le \digamma(t) \le 1\) is a learning-rate schedule. Define</p> \[\bar{\mathbf{g}}(t,i) = \frac{\mathbf{g}(t,i)}{\sqrt{\mathbb{E}[\mathbf{g}(t,i)^2]}},\] <p>where \(\bar{\mathbf{g}}(t,i)\) is the normalized gradient scaled to its unit root-mean-square (RMS) value. The learning rate becomes</p> \[\alpha(t,i) = \mu \digamma(t)\, \frac{\mathbb{E}[\mathbf{w}(t,i) \,\bar{\mathbf{g}}(t,i)]}{\sqrt{\mathbb{E}[\mathbf{g}(t,i)^2]}}.\]<hr /> <h4 id="ema-realizations"> <a href="#ema-realizations" class="anchor-heading" aria-labelledby="ema-realizations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> EMA Realizations </h4> <p>Track the denominator term (moment estimation):</p> \[\mathbf{b}(t,i) = \beta_b \,\mathbf{b}(t-1,i) + (1 - \beta_b) \,\mathbf{g}(t,i)^2,\] <p>and define the RMS-normalizer:</p> \[\mathbf{d}(t,i) = \sqrt{\frac{\mathbf{b}(t,i)}{1 - \beta_b^t}} + \epsilon\] <p>‚Üí bias-corrected RMS-norm with small \(\epsilon\) <a class="citation" href="#honigAdaptiveFiltersStructures1984">(Honig &amp; Messerschmitt, 1984)</a> to prevent division by zero.</p> <p>Track the numerator term:</p> \[\mathbf{a}(t,i) = \beta_a \,\mathbf{a}(t-1,i) + \mu \,\mathbf{w}(t,i) \,\bar{\mathbf{g}}(t,i)\] <p>‚Üí a naive running estimate of the weight‚Äìgradient correlation.</p> <p>Finally:</p> \[\alpha(t,i) = \digamma(t)\,\frac{\mathbf{a}(t,i)}{\mathbf{d}(t,i)}.\] <blockquote> <p><strong>Note:</strong> This learning rate function reduces to only <strong>adaptive moment estimation</strong> when \(\mathbb{E}[\mathbf{w}(t,i) \,\bar{\mathbf{g}}(t,i)]\) is replaced by a fixed constant \(1\).</p> </blockquote> \[\alpha(t,i) = \mu\digamma(t)\,\frac{1}{\mathbf{d}(t,i)}.\]<hr /> <h3 id="robust-ema-estimation"> <a href="#robust-ema-estimation" class="anchor-heading" aria-labelledby="robust-ema-estimation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Robust EMA estimation </h3> <p>In practice, one of the essential properties of a statistical estimator is <strong>robustness</strong>. It describes the resistance property of the estimator against outliers. The robustness of an estimator can be expressed using its <strong>breakdown point</strong> (bigger is better). The breakdown point is the proportion of corrupted inputs that the estimator can handle before outputing an incorrect estimate, and it cannot exceed $0.5$ <a class="citation" href="#huberRobustEstimationLocation1992">(Huber, 1992)</a>. The <strong>breakdown point</strong> of the <strong>EMA</strong> is 0 <a class="citation" href="#zoubirRobustStatisticsSignal2018a">(Zoubir et al., 2018)</a>. This implies only 1 corrupt input sample-point is needed to significantly distort its estimate.</p> <p>The <em>denominator EMA term</em> of the learning rate can be interpreted as a norm of the input gradient signal <a class="citation" href="#boydLinearControllerDesign1991b">(Boyd &amp; Barratt, 1991)</a>, serving as a measure of its energy or magnitude. By normalizing the update through division by this gradient norm, the learning rule becomes scale‚Äënormalized, always adjusted relative to the effective strength of the input. As a result, even when the squared gradient input to the denominator EMA is corrupted by heavy‚Äëtailed noise or occasional outliers, the normalization absorbs these effects. Extreme values in the gradient are proportionally scaled down, preventing instability and ensuring that the update remains bounded and robust.</p> <p>However, the same cannot be said for the <em>numerator EMA term</em>. Whereas the denominator term acts as a norm of the gradient signal and thus provides scale‚Äënormalized robustness, the numerator term directly involves the correlation between a weight and a gradient component. This correlation is inherently more sensitive to noise and outliers: if the weight-gradient product is corrupted, the output of the numerator EMA can be distorted in both magnitude and sign. Unlike the denominator, which absorbs extreme values through normalization, the numerator reflects them directly, potentially leading to erratic updates. In practice, this means that while the denominator stabilizes the learning rate by bounding its scale, the numerator remains the primary channel through which input variability and heavy‚Äëtailed disturbances distort the update step.</p> <p>EMAs assume a well-behaved noise model <a class="citation" href="#huberRobustEstimationLocation1992">(Huber, 1992)</a>. <strong>Heavy‚Äëtailed stochastic correlations, noisy sign flips and occasional magnitude spikes can break this assumption</strong> <a class="citation" href="#zoubirRobustStatisticsSignal2018a">(Zoubir et al., 2018)</a> leading to breakdown.</p> <blockquote> <p>A common empirical safeguard approach in robust estimation to handle such problems are concentration inequality techniques that detect if an input is an outlier, remove the detected outlier then replace with an appropriate value.</p> </blockquote> <p>In this case, we want the estimate of the <strong>numerator EMA</strong> to remain positive, well‚Äëbounded, and avoid corruptions due to noisy, heavy-tailed inputs. In other words, we want to robustify the partial correlation estimate from the EMA without distorting the bulk of the signal observed via its input \(\mathbf{u}(t,i) = \mathbf{w}(t,i) \, \bar{\mathbf{g}}(t,i)\)</p> <h4 id="1-input-clipping"> <a href="#1-input-clipping" class="anchor-heading" aria-labelledby="1-input-clipping"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1. Input Clipping </h4> <p>Heavy-tailed gradient noise statistics induce misleading spikes that can dominate the EMA‚Äôs estimate over many iterations by increasing its bias from the true mean estimate. Since, we do not know the probability distribution, <strong>Markov‚Äôs inequality</strong> gives a rationale for how often large such values can occur. The inequality</p> \[\mathbb{Pr}[|u| \ge c\,\mathbb{E}[|u|] ] \le \frac{1}{c},\] <p>relates how large the magnitude of \(u\) can be relative to its expected magnitude. <strong>Huberisation</strong> <a class="citation" href="#zoubirRobustEstimationSignal2012">(Zoubir et al., 2012; Menon et al., 2020)</a> is a practical way to robustly mitigate such heavy-tailed values via Markov‚Äôs inequality. Instead of naively passing an input \(u\) though the EMA, the Huber clipping function \(\psi_{c}(u)\) can be used to constrain the most extreme outliers (\(c \times\) the expected scale) before they enter the EMA, while avoiding signal dead-zones and allowing moderate estimates to pass through untouched relative to its expected scale.</p> \[\psi_{c}(u) = \begin{cases} u, &amp; |u| \le c\,\mathbb{E}[|u|] \\ \mathrm{sign}(u) \cdot c\,\mathbb{E}[|u|], &amp; |u| &gt; c\,\mathbb{E}[|u|]. \end{cases}\] <p>Here, \(u\) denotes the instantaneous input, and \(c\) is a scale multiplier used to clip only extreme outliers relative to the expected scale. For example, setting \(c=4\) can be viewed as a prior that the probability \(p\) of its magnitude \(|u|\) exceeding four times its mean is no more than \(25\%\). Equivalently, the probability that \(|u|\) remains below this threshold is at least \(1-p=75\%\). Therefore, the interval defined by the 25‚Äì75% quantiles captures the bulk of the distribution, while the clipping function suppresses only the most extreme values. This yields a more <strong>robust EMA estimator</strong> that is less sensitive to heavy‚Äëtailed noise and spurious magnitude spikes.</p> <!-- , and so the probability of the magnitude being less than $$4$$ times its mean is at least $$1-p=75\%$$. T --> <p>Using the instantaneous partial correlation \(\mathbf{u}(t,i)\), we can iteratively estimate its expected scale, via the EMA estimate</p> \[\hat{\mathbf{u}}(t,i) = \beta_a \, \hat{\mathbf{u}}(t-1,i) + (1 - \beta_a)\,|{\mathbf{u}}(t,i)|,\] <p>where \(\hat{\mathbf{u}}(t,i)\) adapts to the typical scale of \(\mathbf{u}(t,i)\) in each layer.</p> <h4 id="2-output-clipping-and-max-normalization"> <a href="#2-output-clipping-and-max-normalization" class="anchor-heading" aria-labelledby="2-output-clipping-and-max-normalization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2. Output Clipping and Max-Normalization </h4> <p>Estimation noise can flip signs of the numerator estimate, artificially inflating or deflating the learning‚Äërate ratio and producing unstable or vanishing steps. The input‚Äëclipping strategy does not account for <strong>spurious sign flips</strong> that slip through the estimator‚Äôs input. When the estimate turns negative, clipping to zero stalls progress entirely. Since the global learning‚Äërate constant \(\mu\) already serves as a safety margin (a trust‚Äëregion), a more robust approach is to design a trust‚Äëregion safeguard around \(\mu\) that <strong>preserves sign information while bounding magnitude.</strong></p> <!-- rather than zeroing negative values outright. --> <p>Thus, we want to ensure the numeric estimate for the partial-correlation stays within a predictable, and reasonable range, while ensuring \(\alpha(t,i) \ge 0\). From the inequality \(0 \le (\mathbf{w}(t,i)-\bar{\mathbf{g}}(t,i))^2\), we have that \(\mathbf{w}(t,i) \,\bar{\mathbf{g}}(t,i) \ \le\ \frac{1}{2}\,\big(\mathbf{w}(t,i)^2 + \bar{\mathbf{g}}(t,i)^2\big),\) and so obtain the max-bound</p> \[\mathbb{E}[\mathbf{w}(t,i) \,\bar{\mathbf{g}}(t,i)] \le \,\mathbb{E}[\mathbf{w}(t,i)^2] + \mathbb{E}[\bar{\mathbf{g}}(t,i)^2] = \mathbb{E}[\mathbf{w}(t,i)^2] + 1.\] <p>\(\mathbb{E}[\mathbf{w}(t,i)^2]\) can be realized by maintaining an EMA estimate</p> \[\mathbf{s}(t,i) = \beta_a \,\mathbf{s}(t-1,i) + (1 - \beta_a) \,\mathbf{w}(t,i)^2,\] <p>and the max-normalizer is \(\bar{\mathbf{s}}(t,i) = 1 + \mathbf{s}(t,i)\).</p> <p>Taken together, using \(\bar{\mathbf{s}}(t,i)\) and \(\mathbf{d}(t,i)\), these practical clipping and normalization techniques, help the partial correlation estimate from the EMA to remain within a predictable dynamic range, preventing large values:</p> \[\tilde{\mathbf{a}}(t,i) = \beta_a \, \tilde{\mathbf{a}}(t-1,i) + \mu\, \bar{\mathbf{s}}(t,i)^{-1}\cdot{\psi_{c} (\mathbf{u}(t,i))}\] <!-- $$ \mathbf{a}(t,i) = \max\bigl(\mu\,\bar{\mathbf{s}}(t,i)^{-1}\cdot\mathbf{d}(t,i),\, \min\bigl( |\tilde{\mathbf{a}}(t,i)|, \, \mu \bigr) \bigr). $$ --> \[\mathbf{a}(t,i) = \max\bigl(0,\, \min\bigl( |\tilde{\mathbf{a}}(t,i)|, \, \mu\,\bar{\mathbf{s}}(t,i) \bigr) \bigr).\] <h4 id="3-layer-wise-smoothing"> <a href="#3-layer-wise-smoothing" class="anchor-heading" aria-labelledby="3-layer-wise-smoothing"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3. Layer-wise smoothing </h4> <p>To account for intra-layer structure and variability in neural networks, we observed that replacing the raw estimates with their layerwise mean, ensured more numerically stable parameter adaptation within each layer. Specifically, for a given layer \(\ell\), with parameter size \(n_\ell\), the numerator update is averaged as</p> \[\mathbf{a}(t,i) ‚Üê \frac{1}{n_\ell} \sum_{i=1}^{n_\ell} \mathbf{a}(t,i).\]<hr /> <!-- ### Alternatives: Relaxed Upper-bound variant Since $$ \mathbf{u}(t,i) = \mathbf{w}(t,i) \,\bar{\mathbf{g}}(t,i) \ \le\ \frac{1}{2}\,\big(\mathbf{w}(t,i)^2 + \bar{\mathbf{g}}(t,i)^2\big), $$ we may replace $$\mathbf{u}(t,i)$$ with a relaxed form of the symmetric upper-bound, $$ \tilde{\mathbf{u}}(t,i) = \mathbf{w}(t,i)^2 + \bar{\mathbf{g}}(t,i)^2$$, weighted by $$ \mu < \frac{1}{2} $$. A proxy estimate of the partial-correlation then becomes $$ \tilde{\mathbf{a}}(t,i) = \beta_a \,\tilde{\mathbf{a}}(t-1,i) + (1 - \beta_a) \,\mu\,\tilde{\mathbf{u}}(t,i). $$ $$ \mathbf{a}(t,i) = \min\bigl( |\tilde{\mathbf{a}}(t,i)|, \, \mu \bigr). $$ Layer-wise smoothing can be applied next. --> <!-- --- --> <h2 id="-unifying-phb-nag-and-adam"> <a href="#-unifying-phb-nag-and-adam" class="anchor-heading" aria-labelledby="-unifying-phb-nag-and-adam"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> üß© Unifying PHB, NAG, and Adam </h2> <p>By choosing \(\beta, \gamma, \alpha(t,i)\) appropriately, AutoSGM recovers</p> <div class="table-wrapper"><table> <thead> <tr> <th style="text-align: center">Algorithm</th> <th style="text-align: center">\(\beta\)</th> <th style="text-align: center">\(\gamma\)</th> <th style="text-align: center">\(\eta\)</th> <th style="text-align: center">\(\alpha(t,i)\)</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Basic</td> <td style="text-align: center">\(0\)</td> <td style="text-align: center">\(0\)</td> <td style="text-align: center">\(0\)</td> <td style="text-align: center">\(\mu \digamma(t)\)</td> </tr> <tr> <td style="text-align: center">PHB</td> <td style="text-align: center">\(‚úì\)</td> <td style="text-align: center">\(0\)</td> <td style="text-align: center">\(1\)</td> <td style="text-align: center">\(\mu \digamma(t)\)</td> </tr> <tr> <td style="text-align: center">NAG</td> <td style="text-align: center">\(‚úì\)</td> <td style="text-align: center">\({\beta}/{(1+\beta)}\)</td> <td style="text-align: center">\((1+\beta)\)</td> <td style="text-align: center">\(\mu \digamma(t)\)</td> </tr> <tr> <td style="text-align: center">Adam</td> <td style="text-align: center">\(‚úì\)</td> <td style="text-align: center">\(0\)</td> <td style="text-align: center">\(1-\beta\)</td> <td style="text-align: center">\({\mu} \digamma(t) \cdot{\mathbf{d}(t,i)}^{-1}\)</td> </tr> </tbody> </table></div> <!-- $$ \begin{array}{l|c} \text{Algorithm} & \gamma \\ \hline \text{PHB} & 0 \\ \text{NAG} & \tfrac{\beta}{1+\beta} \\ \text{Adam} & 0 \\ \end{array} $$ --><hr /> <h2 id="-lowpass-regularization"> <a href="#-lowpass-regularization" class="anchor-heading" aria-labelledby="-lowpass-regularization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> üéØ Lowpass Regularization </h2> <p>Incorporating momentum is known to practically help stabilize learning dynamics and avoid <strong>shallow local minima</strong> <a class="citation" href="#haykinNeuralNetworksLearning2008">(Haykin, 2008)</a>.<br /> In the paper, we use the impulse response of the filter to show that smoothing the gradient (also called momentum) is <strong>approximately equivalent</strong> to smoothing the loss surface:</p> <p>This <strong>Lowpass regularization</strong> due to smoothing the gradient reflects the stabilized training effect of:</p> <ul> <li>reduced noise in the gradient updates,</li> <li>improved convergence to <strong>flatter local minima</strong>,</li> </ul> <p>often observed.</p><hr /> <h2 id="-key-empirical-findings"> <a href="#-key-empirical-findings" class="anchor-heading" aria-labelledby="-key-empirical-findings"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> üìä Key Empirical Findings </h2> <p>Using Adam as a fixed-numerator baseline for the learning rate, we tested the AutoSGM framework using our iteration-dependent learning-rate realization on <strong>CIFAR-10</strong> (ViT, ResNet) and <strong>language modeling</strong> (GPT-2 on WikiText and Shakespeare):</p> <ul> <li><strong>Tuning the filter‚Äôs zero</strong> \(\gamma\) improved performance in most cases.</li> <li><strong>Iteration-dependent learning rate numerator</strong> (circled dots) outperformed fixed numerator (squared dots).</li> </ul> <h3 id="1-gpt-2-on-shakespeare-char-32-lower-test-loss-over-fixed-numerator-baseline"> <a href="#1-gpt-2-on-shakespeare-char-32-lower-test-loss-over-fixed-numerator-baseline" class="anchor-heading" aria-labelledby="1-gpt-2-on-shakespeare-char-32-lower-test-loss-over-fixed-numerator-baseline"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1. GPT-2 on Shakespeare-char: <strong>~32% lower test loss</strong> over fixed-numerator baseline. </h3> <div class="table-wrapper"><table> <tbody> <tr> <td><img src="assets/asgm/gpt2_30M_shake_tr.png" width="300" /></td> <td><img src="/assets/asgm/gpt2_30M_shake_tr.png" width="300" /></td> </tr> </tbody> </table></div> <h3 id="2-vit-on-cifar10"> <a href="#2-vit-on-cifar10" class="anchor-heading" aria-labelledby="2-vit-on-cifar10"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2. VIT on CIFAR10. </h3> <div class="table-wrapper"><table> <tbody> <tr> <td><img src="./assets/asgm/vit_cifar10_tr.png" width="300" /></td> <td><img src="./assets/asgm/vit_cifar10_tt.png" width="300" /></td> </tr> </tbody> </table></div> <h3 id="3-resnet18-on-cifar10"> <a href="#3-resnet18-on-cifar10" class="anchor-heading" aria-labelledby="3-resnet18-on-cifar10"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3. ResNet18 on CIFAR10. </h3> <div class="table-wrapper"><table> <tbody> <tr> <td><img src="./assets/asgm/resnet_cifar10_tr.png" width="300" /></td> <td><img src="./assets/asgm/resnet_cifar10_tt.png" width="300" /></td> </tr> </tbody> </table></div> <h3 id="4-gpt-2-on-wikitext-103"> <a href="#4-gpt-2-on-wikitext-103" class="anchor-heading" aria-labelledby="4-gpt-2-on-wikitext-103"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4. GPT-2 on WikiText-103. </h3> <div class="table-wrapper"><table> <tbody> <tr> <td><img src="./assets/asgm/gpt2_124M_wiki_tr.png" width="300" /></td> <td><img src="./assets/asgm/gpt2_124M_wiki_tt.png" width="300" /></td> </tr> </tbody> </table></div><hr /> <h2 id="-conclusion"> <a href="#-conclusion" class="anchor-heading" aria-labelledby="-conclusion"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> üèÅ Conclusion </h2> <p>AutoSGM offers a <strong>unified, interpretable, and tunable</strong> framework for what has traditionally been referred to as momentum-based optimization.</p> <p>We can operate PHB, NAG, and Adam as points in the <strong>AutoSGM parameter space</strong>.</p> <p>Overall AutoSGM is a foundational framework for studying stochastic gradient algorithms, enabling systematic separation of filter design, automatic learning-rate function choices and the non-unique implementations present in current methods.</p> <!-- - Design **new stochastic gradient optimizers** with principled stability and error bounds. - Achieve **better generalization** through lowpass regularization. - Improve **learning rate algorithms**. --><hr /> <p>üí° <em>Takeaway:</em> If you have been switching between Adam, NAG, and PHB, you might not need to. They are all part of the same family. <strong>AutoSGM gives you the structure or map</strong>.</p><hr /> <ol class="bibliography"><li><span id="bottouOptimizationMethodsLargescale2018">Bottou, L., Curtis, F. E., &amp; Nocedal, J. (2018). Optimization Methods for Large-Scale Machine Learning. <i>SIAM Review</i>, <i>60</i>(2), 223‚Äì311.</span></li> <li><span id="moonMathematicalMethodsAlgorithms2000">Moon, T. K., &amp; Stirling, W. C. (2000). <i>Mathematical Methods and Algorithms for Signal Processing</i>. Prentice Hall.</span></li> <li><span id="vantreesDetectionEstimationModulation2013">Van Trees, H. L., Bell, K. L., &amp; Tian, Z. (2013). <i>Detection Estimation and Modulation Theory, Detection, Estimation, and Filtering Theory, Part I</i> (2nd ed.). Wiley.</span></li> <li><span id="dinizAdaptiveFilteringAlgorithms2020">Diniz, P. S. R. (2020). <i>Adaptive Filtering: Algorithms and Practical Implementation</i> (5th edition). Springer International Publishing. https://doi.org/10.1007/978-3-030-29057-3</span></li> <li><span id="haykinAdaptiveFilterTheory2014">Haykin, S. (2014). <i>Adaptive Filter Theory</i> (5th, intern.). Pearson.</span></li> <li><span id="honigAdaptiveFiltersStructures1984">Honig, M. L., &amp; Messerschmitt, D. G. (1984). <i>Adaptive Filters: Structures, Algorithms and Applications</i>. Kluwer Academic Publishers.</span></li> <li><span id="huberRobustEstimationLocation1992">Huber, P. J. (1992). Robust Estimation of a Location Parameter. In S. Kotz &amp; N. L. Johnson (Eds.), <i>Breakthroughs in Statistics: Methodology and Distribution</i> (pp. 492‚Äì518). Springer. https://doi.org/10.1007/978-1-4612-4380-9_35</span></li> <li><span id="zoubirRobustStatisticsSignal2018a">Zoubir, A. M., Koivunen, V., Ollila, E., &amp; Muma, M. (2018). <i>Robust Statistics for Signal Processing</i> (1st ed.). Cambridge University Press. https://doi.org/10.1017/9781139084291</span></li> <li><span id="boydLinearControllerDesign1991b">Boyd, S., &amp; Barratt, C. (1991). <i>Linear Controller Design: Limits of Performance</i>. Prentice Hall.</span></li> <li><span id="zoubirRobustEstimationSignal2012">Zoubir, A. M., Koivunen, V., Chakhchoukh, Y., &amp; Muma, M. (2012). Robust Estimation in Signal Processing: A Tutorial-Style Treatment of Fundamental Concepts. <i>IEEE Signal Processing Magazine</i>, <i>29</i>(4), 61‚Äì80.</span></li> <li><span id="Menon2020GradientClipping">Menon, A. K., Rawat, A. S., Reddi, S. J., &amp; Kumar, S. (2020). Can Gradient Clipping Mitigate Label Noise? <i>Proceedings of the 8th International Conference on Learning Representations</i>.</span></li> <li><span id="haykinNeuralNetworksLearning2008">Haykin, S. (2008). <i>Neural Networks and Learning Machines</i> (3rd edition). Pearson.</span></li></ol> <hr> <h2 class="text-delta">Table of contents</h2> <ul> <li> <a href="/learning_dynamics">Learning Dynamics</a> </li> </ul> </main> <hr> <footer> <p><a href="#top" id="back-to-top">Back to top</a></p> <div class="d-flex mt-2"> <p class="text-small text-grey-dk-000 mb-0 mr-2"> Page last modified: <span class="d-inline-block">Oct 9 2025 at 12:00 AM</span>. </p> </div> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
