
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>AutoSGM Quadratic Function Sim.</title>

  <script>
    window.MathJax = {
      loader: {load: ['[tex]/color']},
      tex: {          
        inlineMath: [['$', '$'], ['\\(', '\\)']],        
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        packages: { '[+]': ['color']},
        tags: 'ams',        
        macros: {
          rw: "\\textrm{w}",
          rwt: "\\textcolor{OliveGreen}{\\rw_t}",
          rwtp: "\\textcolor{OliveGreen}{\\rw_{t+1}}",
          rmt: "\\textcolor{OrangeRed}{m_t}",
          rmtp: "\\textcolor{OrangeRed}{m_{t+1}}",
          rmtm: "\\textcolor{OrangeRed}{m_{t-1}}",
          rst: "\\textcolor{OrangeRed}{s_t}",
          rstp: "\\textcolor{OrangeRed}{s_{t+1}}",
          rstm: "\\textcolor{OrangeRed}{s_{t-1}}",
          rg: "\\textrm{g}",
          rv: "\\textrm{v}",
          rh: "\\textrm{h}",
          rH: "\\mathbf{H}",
          rc: "\\textrm{c}",
          rx: "\\textrm{x}",
          rxt: "\\rx_t",
          rxtp: "\\rx_{t+1}",
          rxtm: "\\rx_{t-1}",
          rq: "\\textrm{q}",
          rqt: "\\rq_t",
          rqtp: "\\rq_{t+1}",
          rqtm: "\\rq_{t-1}",          
          rxi: "\\rx_0",
          rr: "\\textrm{r}",
          rrt: "\\rr_t",
          rA: "\\mathbf{A}",
          rB: "\\mathbf{B}",
          gradt: "\\textcolor{RoyalBlue}{\\rg_{t}}",
          gradtm: "\\textcolor{RoyalBlue}{\\rg_{t-1}}",          
          gradvt: "\\textcolor{RoyalBlue}{\\rv_{t}}",
          gradvtm: "\\textcolor{RoyalBlue}{\\rv_{t-1}}",
        },
      },
      options: {
        renderActions:  { addMenu: [], assitveMml: [] },
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      svg: {
          fontCache: 'none'
      }
    };
  </script>  
  <script id="MathJax-script" type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>

  <script src="https://cdn.plot.ly/plotly-3.1.2.min.js" charset="utf-8"></script>

  <!-- CSS file in the same folder -->
  <link rel="stylesheet" href="quad_sim.css">

  <!-- <script
  type="text/javascript"
  src="https://cdn.jsdelivr.net/npm/three@0.137.0/build/three.min.js"
></script>
<script
  type="text/javascript"
  src="https://cdn.jsdelivr.net/npm/three@0.137.0/examples/js/controls/OrbitControls.js"
></script>
<script
  type="text/javascript"
  src="https://cdn.jsdelivr.net/npm/mathbox@latest/build/bundle/mathbox.js"
></script> -->

<div style="display: none;">
$$
\newcommand{\errt}{\textcolor{RubineRed}{\varepsilon_t}}
\newcommand{\errtm}{\textcolor{RubineRed}{\varepsilon_{t-1}}}
\newcommand{\errtp}{\textcolor{RubineRed}{\varepsilon_{t+1}}}
\newcommand{\errti}{\textcolor{RubineRed}{\varepsilon_0}}
\newcommand{\derrtp}{\textcolor{RubineRed}{\Delta\varepsilon_{t+1}}}
\newcommand{\derrt}{\textcolor{RubineRed}{\Delta\varepsilon_{t}}}
\newcommand{\derrti}{\textcolor{RubineRed}{\Delta\varepsilon_{0}}}
$$
$$
\newcommand{\mean}[1]{\mathbb{E}[#1]}
\newcommand{\mgradt}{\mean{\gradt}}
\newcommand{\mgradtm}{\mean{\gradtm}}
\newcommand{\merrt}{\mean{\errt}}
\newcommand{\merrtm}{\mean{\errtm}}
\newcommand{\merrtp}{\mean{\errtp}}
\newcommand{\mderrtp}{\mean{\derrtp}}
\newcommand{\mderrt}{\mean{\derrt}}
$$ 
$$
\newcommand{\sgradt}{{\gradt^2}}
\newcommand{\sgradtm}{{\gradtm^2}}
\newcommand{\serrt}{{\errt^2}}
\newcommand{\serrtm}{{\errtm^2}}
\newcommand{\serrtp}{{\errtp^2}}
\newcommand{\sderrtp}{{\derrtp^2}}
\newcommand{\sderrt}{{\derrt^2}}
$$   
$$
\newcommand{\vgradt}{\mean{\gradt^2}}
\newcommand{\vgradtm}{\mean{\gradtm^2}}
\newcommand{\verrt}{\mean{\errt^2}}
\newcommand{\verrtm}{\mean{\errtm^2}}
\newcommand{\verrtp}{\mean{\errtp^2}}
\newcommand{\vderrtp}{\mean{\derrtp^2}}
\newcommand{\vderrt}{\mean{\derrt^2}}
$$   
</div>

</head>

<body>     

<div class="container">

    <div class="item-head">

      <div class="note-container" role="region">
        <div class="note-header">
          <div class="note-progress" aria-live="polite" id="note-progress">1 / 3</div>
        </div>
      
        <div class="note-viewport" aria-live="polite" aria-atomic="true">
          <div class="note-track" id="note-track">
            <section class="note ">
              <div class="hero-banner">
                <div class="hero-content">
                  <h1> <span class="cgreen"> Auto</span>SGM</h1>
                  <h2><span class="highlight"> Two Steps. Zero Error.</span></h2>
                  <p class="tagline">
                    <span class="cgray"><strong>Momentum</strong> beyond intuition</span>: a principled <strong>signal-processing</strong> framework certifying stable, accelerated learning.
                  </p>
                </div>   
              </div>  
              <div class="cover">

                  <p>
                    The word <strong>momentum</strong> has always promised speed. But, what exactly is momentum?  
                    Classic explanations give intuition.
                    Mostly, they show us <strong>why</strong> momentum helps, not <strong>how to design it</strong> for guaranteed performance.
                  </p>
                
                  <p>
                    <strong>The AutoSGM framework changes that.</strong> In this notes, using a deceptively simple problem setup that captures the essence of more complex scenarios, we recast the stochastic gradient dynamics as a 
                    <em>linear-time invariant system</em>, derive explicit stability certificates, and uncover automatic learning-rate rules for convergence of the learning algorithm. The outcome is a principled recipe that:
                  </p>
                
                  <ul class="key-points">
                    <li>Provides closed-form formulas for the learning-rate, and other system parameters.</li>
                    <li>Guarantees exponential convergence in the mean, across all admissible momentum parameter values. Error collapses to zero in at most 2 iterations.</li>
                    <li>Offers an interpretable lens on learning using signal-processing and control tools.</li>
                  </ul>
                
                  <h3>✨ Why AutoSGM?</h3>
                  <p>
                   In this problem setup, the AutoSGM framework goes further. It unifies momentum (gradient smoothing in the stochastic gradient method) and turns it into a <strong>precisely engineered system</strong>, 
                    with parameters chosen to guarantee mean error convergence across the admissible 'momentum' parameter range in just two steps. 
                    Where classic, special cases trade off speed and stability, with AutoSGM we deliver a <strong>closed-form certificate</strong> for both.
                  </p>
                  <div class="coverteaser">
                    These results hold exactly under a quadratic loss, diagonal Hessian setting. 
                    <p>
                     Outside such setting, AutoSGM does not literally guarantee a two-step convergence. But its system-theoretic perspective continues to offer valuable intuition towards principled parameter choices. 
                    </p>
                  </div>
              </div>
            </section>

            <section class="note">
              <h4 id="note-title-0">Problem setup</h4>
              Consider the simple but representative problem of minimizing, at each time-step or iteration $t>0$, a twice-differentiable, weighted quadratic loss function, 

              $$f(\rwt) = \tfrac{1}{2} u_t^2 \cdot \errt^2,$$

              where the model is a 1-dimensional parameter-vector $\rwt$, the error relative to an optimum value $\rw^*$ is $\errt = \rwt - \rw^* $, and the weighting variable $u_t$ is modeled as a wide-sense stationary, zero-mean Gaussian data process, statistically independent of the error. 
              
              <p>This implies $u_t$ has a mean $\mean{u_t} = 0$, a finite second-moment (or variance) $\mean{u_t^2} = λ$, with $0<\lambda<\infty$, and uncorrelated values across time $\mean{u_t\,u_k} = 0, \hbox{for } t\ne k$. Independence further implies that for any powers $i,j$, the joint moment $\mean{u_t^i \errt^j} = \mean{u_t^i}\mean{\errt^j}$.</p>

              Differentiating $f(\rwt)$ with respect to $\rwt$, we get the gradient $\gradt$ and Hessian $\rH_t$ as follows,
              $$ \begin{align}
              \gradt =  \nabla f(\rwt) =  u_t^2\cdot \varepsilon_t, & \quad \mean{\gradt} = \lambda\, \mean{\errt}.\\
              \rH_t =  \nabla^2 f(\rwt) =  u_t^2,& \quad \mean{\rH_t} = \lambda.
              \end{align}
              $$
              
              To minimize  $f(\rwt)$, an optimization algorithm of choice is known as the
              <strong>Stochastic Gradient Method</strong> (SGM). The simplest form of this algorithm is an iterative update rule of the form 
              $$ \rwtp = \rwt - \alpha_t \, \gradt.$$ 
              
              At each iteration, the update rule receives an $\alpha_t > 0$ from a <strong>learning rate</strong> oracle and $\gradt$ from a gradient-generating oracle. Although, the algorithm updates $\rwt$ by taking a step in the direction of the gradient, it does not strictly assume its input is either <strong>exact</strong> or <strong>stochastic</strong>, nor does it guarantee a  <strong>descent</strong> of $f(\rwt)$ per iteration. Nonetheless, the notions of stochasticity and descent have become commonly associated with the update rule, even if they are not required for it to function.

              $$ \errtp = \errt - \alpha_t \, \gradt.$$ 
              <p>
              We will further assume that the system dynamics are linear time-invariant (LTI). This means $\alpha_t = \alpha, \forall t$, a constant learning rate across iterations, and so
              $$ \errtp = \errt - \alpha \, \gradt.$$ 
              
              <strong>Goal</strong>. In this controlled and interpretable setting, we desire that the algorithm drives its error, starting from any initial non-zero value $\errti$, to converge to its optimum value of <strong>zero</strong> in approximately one or two iterations. 
              </p>

              <div class="teaser">
              As we move forward, we will discover that <b>ensuring convergence</b> in this setting is equivalent to certifying the <b>stability conditions</b> of LTI filters.
              </div>
              
              
              <!-- <details>
                <summary>Show derivation</summary>
                <p>For quadratic \( f(x) = \tfrac{1}{2}x^\top H x \), \( \nabla f(x) = Hx \), hence \( x_{t+1} = (I - \alpha H)x_t \).</p>
              </details>
              <blockquote>Tip: Slide the plot’s step size to see contraction change.</blockquote> -->
            </section>
      
            <section class="note" >
              <h4 id="note-title-1"> Error Dynamics (Mean Convergence)</h4>

              <p>
              Recall that $\gradt = u_t^2\cdot \errt$, we can write the error equation as $\errtp =  \errt +  \derrtp$, where $\derrtp = -\alpha \, \gradt$,
              from which we get $\gradt = u_t^2\cdot \errtm + u_t^2\cdot \derrt$, and the dynamics
              </p>

              $$
              \begin{equation}              
              \label{eq:smc1}
              \begin{aligned} 
              \derrtp &= -\alpha u_t^2 \cdot \derrt -\alpha u_t^2 \cdot \errtm \\ 
              \errt &= \derrt + \errtm.
              \end{aligned}
              \end{equation}

              $$

              Note that $\mean{u_t^2} = \lambda$. Taking expectation of the terms in ($\ref{eq:smc1}$), and denote $\rmt = \merrt$, $\rst = \mderrt$, $\beta_p = -\alpha \lambda$, and $k_p = -\alpha \lambda$, the expected error dynamics is

              $$
              \begin{equation}\label{eq:smeq}
              \boxed{
              \begin{aligned} 
              \rstp &= \beta_p\,\rst + k_p \, \rmtm \\ 
              \rmt &= \rst + \rmtm
              \end{aligned}}.
              \end{equation}
              $$ 


              Equation $(\ref{eq:smeq})$, tells us that the expected error $\rmt$ is the sum of the expected change-level error $\rst$, and that the expected change-level error dynamics is that of a single-pole LTI filter,
              $$\rstp = \beta_p\,\rst + k_p \, \rmtm$$ with input $\rmtm$, its transfer-function is 
              $$H_{s}(z) = \frac{k_p}{1-\beta_p\,z^{-1}}.$$

              The change-level system $H_{s}(z)$ is both asymptotically and exponentially stable if its single pole satisfies $\lvert \beta_p\rvert < 1$. Since $\alpha >0$, $\beta_p = -\alpha \lambda$ is negative, this translates to $-1 < -\alpha\lambda < 0$, that is $1 > \alpha\lambda$, and $\alpha\lambda > 0$, which imply

              $$\begin{equation}\label{eq:mewin}
              \boxed{0 < \alpha < \tfrac{1}{\lambda}}.
              \end{equation}$$ 
              
              The overall dynamics of the expected error, written in matrix form is
              $$
              \begin{equation}
              \underbrace{
              \begin{bmatrix}
              \rstp \\
              \rmt
              \end{bmatrix}
              }_{\rxt}
              =
              \underbrace{
              \begin{bmatrix}
              \beta_p & k_p \\
              1 & 1
              \end{bmatrix}
              }_{\rA}
              \underbrace{
              \begin{bmatrix}
              \rst \\
              \rmtm
              \end{bmatrix}
              }_{\rxtm}.
              
              \label{eq:smeqmat}
              \end{equation}
              $$
              Compactly, the two-state LTI system is $\rxt = \rA^{t}\,\rxi$.
              Again, exponential and asymptotic stablility of the two-state  system requires its eigenvalues, $z_1 = 0$, and $\textcolor{Mahogany}{z_2 =1-\alpha\lambda}$ roots of the characteristic polynomial $\det(z\mathbf{I}-\mathbf{A}) = z(z-(1-\alpha\lambda)) = 0 $ to be distinct and have a magnitude strictly less than 1. The maximum system eigenvalue $\lvert z_2 \rvert < 1$, implies $-1 < 1-\alpha\lambda < 1$, and so $2>\alpha\lambda$, and $\alpha\lambda > 0$, meaning  $0 < \alpha < \tfrac{2}{\lambda}$. 

              <p>
              By eigenvalue decomposition of the rank-1 system matrix in $\rxt = \rA^{t}\,\rxi$, and taking any consistent norm $\|\cdot\|$ of both sides, we can obtain a certificate on the exponential convergence of the expected error states as
              $$ \boxed{\| \rxt \| \le \tfrac{2}{1+\beta_p} \cdot |\textcolor{Mahogany}{z_2}|^{t}\, \|\rxi\|}.$$
              </p>
            </section>
      
            <section class="note">
              <h4 id="note-title-2">Reflections: Mean Convergence</h4>
              The main results from the error convergence in the mean-sense are the stricter range
              $$
              \boxed{0 < \alpha < \tfrac{1}{\lambda}},
              $$
              and the covergence bound
              $$ \boxed{\| \rxt \| \le \tfrac{2}{1+\beta_p} \cdot |\textcolor{Mahogany}{z_2}|^{t}\, \|\rxi\|},
              $$   
              where we denoted
              $\rxt$ as the two-state vector       
              $\mean{\begin{bmatrix}
              \derrtp\quad\errt
              \end{bmatrix}}^{\top}
              $.
              
              <h5>Play with the controls </h5>
              <ol>
                <li>Click on the RAW-M button</li>
                <li>Ensure the Input selector reads Step </li>
                <li>Click Play, to watch the sweep $0 < \alpha < \tfrac{1}{\lambda}$</li>
              </ol>
              
              <ol>
                <li>Click on the Pause button</li>
                <li>Change the Input selector to read Impulse</li>
                <li>Click Play, to watch the sweep $0 < \alpha < \tfrac{1}{\lambda}$. Pause. </li>
              </ol>
            
              <b>Observations </b>
              <ol>
                <li> <b>Coupling</b>. Once, the change-level error diverges, the actual error also diverges.
                </li>
                <li>
                  The sweep of all choices in $0 < \alpha < \tfrac{1}{\lambda}$ is sufficient to stabilize the error's impulse response.
                </li>
                <li>
                  However, the same cannot be said for the error's step response, which is what we care about the most. It appears we need a tighter range to certify an error response that converges quickly.
                </li>                
                <li>
                  Values of $\alpha$ extremely close to zero yield slow but monotonic convergence.
                </li>
                <li>
                  In contrast, approaching $\alpha = \tfrac{1}{\lambda}$ practically, leads to highly oscillatory and divergent-looking behavior.
                </li>
                <li>
                  <b>Design Gap</b>. No single choice of $\alpha$ in this range gets us close to our true goal. The fastest we can go is not ripple-free.
                </li>
              </ol>
              
              <div class="teaser">The good news, is that we can obtain a much tighter and practical certificate, by analyzing the mean-square convergence of the error.
              </div>

              <p>
              In the next page, we will see that by analyzing convergence of the error in the mean-square sense, we get a tighter, strict certificate on the choice of the learning-rate
              $$
              \boxed{0 < \alpha \le \tfrac{1}{\sqrt{3}}\cdot\tfrac{1}{\lambda},} 
              $$ 
              </p>
              and further, matching the mean-square convergence rate to the mean convergence rate in this range leads to the choice
              $$
              \boxed{\alpha = \tfrac{1}{3}\cdot\tfrac{1}{\lambda}}.
              $$ 

            </section>
           
            <section class="note">
              <h4 id="note-title-3">Error Dynamics (Mean-square Convergence)</h4>
                We start by squaring the recursions in (\ref{eq:smc1}), which yields
                $$
                \begin{equation}              
                \label{eq:sqmc1}
                \begin{aligned} 
                \sderrtp &= \alpha^2 u_t^4 \cdot \sderrt - \alpha^2 u_t^4 \cdot \bigl(\serrtm - 2\,\errt\errtm \bigr), \\ 
                \serrt &= \sderrt - \serrtm + 2\,\errt\errtm.
                \end{aligned}
                \end{equation}
                $$                 
                Note that $\mean{u_t^4} = 3 \lambda^2$.
                Taking expectation of the terms in ($\ref{eq:sqmc1}$), and denoting $\rmt = \verrt$, $\rst = \vderrt$, $\beta_v = 3\,\alpha^2 \lambda^2$, and $k_v = -3\,\alpha^2 \lambda^2$, the mean-square error dynamics is
                $$
                \begin{equation}\label{eq:sqmeq}
                \boxed{
                \begin{aligned} 
                \rstp &= \beta_v\,\rst + k_v \bigr(\rmtm -  2\,\mean{\errt\errtm}\bigr)\\ 
                \rmt &= \rst - \rmtm + 2\,\mean{\errt\errtm}.
                \end{aligned}}
                \end{equation}
                $$ 
                Equation $(\ref{eq:sqmeq})$, tells us that the expected change-level squared error dynamics is that of a single-pole LTI lowpass filter,
                $\rstp = \beta_v\,\rst + k_v \, y_t$, with input $y_t = \rmtm -  2\,\mean{\errt\errtm}$, its transfer-function is 
                $$H_{v}(z) = \frac{k_v}{1-\beta_v\,z^{-1}}.$$
  
                The change-level system $H_{v}(z)$ is both asymptotically and exponentially stable if its single pole satisfies $\lvert \beta_v\rvert < 1$. Since $\alpha >0$, and $\beta_v = 3\,\alpha^2 \lambda^2 > 0$ this translates to $0 < 3\alpha^2\lambda^2 < 1$,  which imply
                $$
                \begin{equation}\label{eq:sqmewin}
                \boxed{0 < \alpha < \tfrac{1}{\sqrt{3}}\tfrac{1}{\lambda}}. 
                \end{equation}
                $$ 
              
                Denote $ \rc_t =\mean{\errt\errtm}$. The overall dynamics, written in matrix form is
                $$
                \begin{align}
                \underbrace{
                \begin{bmatrix}
                \rstp \\
                \rmt
                \end{bmatrix}
                }_{\rxt}
                =
                \underbrace{
                \begin{bmatrix}
                \beta_v & k_v \\
                1 & -1
                \end{bmatrix}
                }_{\rA}
                \underbrace{
                \begin{bmatrix}
                \rst \\
                \rmtm
                \end{bmatrix}
                }_{\rxtm}
                +
                \underbrace{
                  \begin{bmatrix}
                  2\,k_v & 0 \\
                  2 & 0
                  \end{bmatrix}
                  }_{\rB}
                  \underbrace{
                  \begin{bmatrix}
                 \rc_t \\
                  0
                  \end{bmatrix}
                  }_{\rrt}.
                \label{eq:sqmeqmat}
                \end{align}
                $$
               
               Stability of the LTI system requires the magnitude of the eigenvalues of $\rA$, $\lvert z_1 \rvert = 0$, and $\textcolor{Mahogany}{\lvert z_2 \rvert = \lvert 1-3\,\alpha^2\lambda^2 \rvert}$ obtained via $\det(z\mathbf{I}-\rA)=0 $ to be distinct and strictly less than 1. 
                Assume the overall system input is bounded, $\sup_t \lvert \rrt \rvert \le R,\quad 0 < R< \infty$, we can obtain the stability certificate for the error's mean-square convergence as
                $$
                \boxed{
                  \|\rxt\| \le \tfrac{2}{1-\beta_v}\Bigl( \textcolor{Mahogany}{\lvert z_2 \rvert } ^t \|\rxi\| + 2\,R\, \tfrac{1-\textcolor{Mahogany}{\lvert z_2 \rvert } ^t}{1-\textcolor{Mahogany}{\lvert z_2 \rvert }} \Bigr)
                }.
                $$
                Equating the maximum eigenvalue magnitude for the mean-square covergence to that for the mean covergence obtained previously,
                $\lvert 1 - 3\,\alpha^2\lambda^2 \rvert = \lvert 1 - \alpha \lambda \rvert$, so that approximately, both converge to $0$ at the same rate, we get
                $$
                \boxed{\alpha = \tfrac{1}{3\,\lambda}}.
                $$

            </section>

            <section class="note">
              <h4 id="note-title-4">Reflections: Error Convergence</h4>
              $$ \errtp = \errt - \alpha \, \gradt.$$ 
              The main results to additionally guarantee error convergence in the mean-square sense are the stricter range
              $$
              \boxed{0 < \alpha < \frac{1}{\sqrt{3}\lambda}} < \frac{1}{\lambda}, 
              $$
              or the <strong>matched mean rate to mean-square rate </strong> choice
              $$
              \boxed{\alpha = \frac{1}{3\,\lambda}} < \frac{1}{\sqrt{3}\lambda}.
              $$
              
              <h5>Play with the controls </h5>
              <ol>
                <li>Click on the RAW-M button. This automatically sets $\alpha = \tfrac{1}{3\lambda}$. </li>
                <li>Ensure the Input reads either Step or Impulse </li>
                <li>Observe, the overall system response. </li>
              </ol>
              
              <ol>
                <li>Click on the RAW-L button. This automatically sets $\alpha = \tfrac{1}{\sqrt{3}\lambda}$. </li>
                <li>Ensure the Input reads either Step or Impulse</li>
                <li>Observe, the overall system response. </li>
              </ol>
            
              <b>Observations </b>
              <ol>            
                <li>
                  The marginally stable $\alpha = \tfrac{1}{\sqrt{3}\lambda}$ is tight, but we need to tolerate minimal ripples.
                </li>
                <li>
                  The smaller $\alpha = \tfrac{1}{{3}\lambda}$, gives the same behavior, ripple-free, but a tiny-bit slower.
                </li>
                <li>
                  <b>Design Gap</b>. No single $\alpha$ within the stability range achieves our true goal.
                </li>
              </ol>
              
              <div class="teaser">The better news, is that we can still achieve our goal. In fact, we can do that with a much lesser effort and less stress than we have just gone through.
        
              <p>
              In the next page, we will introduce the <b>AutoSGM</b> structure that helps us achieve our <strong>at most two-step convergence goal</strong>, by smoothing (lowpass regularization of) the raw gradient input to the SGM via the means of a LTI filter.
              </p>
              This has been called <b>momentum</b> in classic optimization and mainstream machine learning.
              <p>
              In other words, the SGM algorithm now uses a smooth version of the gradient, replace $\gradt$ with a smooth version $\gradvt$, and the error recursion becomes
              $$ \errtp = \errt - \alpha \, \gradvt.$$ 
              </p>
              </div>
              Still, the same SGM, the <strong>key difference</strong> is that the algorithm's input is now adorned with a better cloth.

            </section>
           
            <section class="note">
              <h4 id="note-title-5">AutoSGM</h4>
              <p>
                The SGM algorithm now uses a smooth version of the gradient, we replace $\gradt$ with a smooth version $\gradvt = H_{\beta,\gamma}(z) \{ \gradt \}$,
                \[
                  H_{\beta,\gamma}(z) = \eta\,\frac{1 - \gamma z^{-1}}{1 - \beta z^{-1}}.
                \]
                In the transfer-function, we have the filter's pole $ 0 < \beta < 1$ , the filter's zero $ \gamma \le \beta $, and $0 < \eta \le 1$. Here, we will always ensure the D.C gain of the filter is $1$, that is, $\eta = \tfrac{1-\beta}{1-\gamma}$.
              </p>
              <p>
                The update rule is now
                $
                  \rwtp = \rwt - \alpha \, \gradvt,
                $
                using the error, we have
                $$
                \errtp = \errt - \alpha \, \gradvt.
                $$
              </p>

              A causal realization of this first-order LTI filter is
              $$
                \gradvt = \beta \, \gradvtm + \eta\,\big(\gradt - \gamma \, \gradtm \big).
              $$
              Therefore, we directly get an explicit change-level dynamics that inherits the lowpass structure of  $H_{\beta,\gamma}(z)$,
              \[
                \derrtp = \errtp - \errt = -\alpha \, \gradvt.
              \]
              </p>
              In general, for any choice of $(\beta,\gamma)$, the filter's  canonical realization is
              \[ 
              \boxed{
              \begin{aligned}
              \rqt &= \beta \, \rqtm + \gradt\\
              \gradvt &= \eta\,(\rqt - \gamma\,\rqtm)
              \end{aligned}}.
              \]
              <div class="teaser">
                <p>
                  Tuning $\gamma$ recovers classic methods, which often use $\eta= \tfrac{1}{1-\gamma}$.
                </p>

                <ul class="clist1">
                <li>
                Heavy-Ball sets $\gamma = 0$, the realization simplifies to
                $\gradvt = \beta \, \gradvtm + \eta\,\gradt$.            
                </li>

                <li>
                Nesterov's Accelerated Gradient (NAG) sets $\gamma = \tfrac{\beta}{1+\beta}$, the realization simplifies to
                \[
                \begin{aligned}
                \rqt &= \beta \, \rqtm + \,\gradt\\
                \gradvt &= \frac{\eta(\beta \, \rqt + \gradt)}{1+\beta} .
                \end{aligned}
                \]                
                </li>
                </ul>
              </div>

              The change-level now takes the appearance of a lowpass filter
              \[
                \derrtp = \beta \, \derrt + \alpha\,\eta\,\bigl(\gamma\,\gradtm - \gradt \bigr),
              \]
              instead of the former version
              \[
                \derrtp = -\alpha\,\gradt.
              \]

              <div class="teaser">
                All is now set. Next, we analyze the mean error dynamics. <strong>We will see that this lowpass regularizing structure gets us to our goal.</strong>
              </div>

            </section>
 
            <section class="note">
              <h4 id="note-title-6">AutoSGM: Error Dynamics (Mean Convergence)</h4>
              <p>
                Recall that $\mgradt = \lambda\,\merrt$, and that $\merrt =  \merrtm +  \mderrt$, so that $\mgradt = \lambda\,\merrtm + \lambda\,\mderrt$, and $\merrtp = \beta \, \mderrt + \alpha\,\eta\,\bigl(\gamma\,\mgradtm - \mgradt \bigr) $.
                <br/><br/>
                Denote $\beta_p = \beta - \alpha\,\eta\,\lambda $, and $k_p = - \alpha\,\eta\,\lambda\,(1-\gamma)$, $\rmt = \merrt$, $\rst = \mderrt$, to get
                $$
                \begin{equation}              
                \label{eq:ac1}
                \begin{aligned} 
                \rstp &= \beta_p\,\rst + k_p\,\rmtm \\ 
                \rmt &= \rst + \rmtm.
                \end{aligned}
                \end{equation}
                $$
              </p>
                The lowpass filtered change-level system is both asymptotically and exponentially stable if its single pole satisfies $0 < \beta_p < 1$. Since $ 0< \beta < 1 $, and $\alpha > 0$, then $0 < \beta - \alpha\,\eta\,\lambda < \beta $ translates to $0 < \alpha\,\eta\,\lambda  < \beta$, which imply
    
                $$\begin{equation}\label{eq:alrwin}
                  \boxed{0 < \alpha < \tfrac{\beta}{\eta}\,\tfrac{1}{\lambda}}.
                  \end{equation}
                $$ 
                
                The overall dynamics of the expected error, written in matrix form is
                $$
                \begin{equation}
                \underbrace{
                \begin{bmatrix}
                \rstp \\
                \rmt
                \end{bmatrix}
                }_{\rxt}
                =
                \underbrace{
                \begin{bmatrix}
                \beta_p & k_p \\
                1 & 1
                \end{bmatrix}
                }_{\rA}
                \underbrace{
                \begin{bmatrix}
                \rst \\
                \rmtm
                \end{bmatrix}
                }_{\rxtm}.
                
                \label{eq:amsyseq}
                \end{equation}
                $$
                Compactly, the two-state LTI system is $\rxt = \rA^{t}\,\rxi$. Notice that since $\beta_p \ne k_p$, <b>the system matrix is now full-rank</b>. <br><br>
                The characteristic polynomial $\det(z\mathbf{I}-\mathbf{A}) = 0$ gives $z^2 -(1+\beta_p)\,z + (\beta_p-k_p) = 0 $, where $\beta_p-k_p = \beta - \alpha\,\eta\,\lambda\,\gamma$. Let $D = (1+\beta_p)^2 - 4\,(\beta_p-k_p)$, the two system eigenvalues are               
                $
                z_{1,2} = \tfrac{1+\beta_p}{2} \pm \tfrac{\sqrt{D}}{2}.
                $
                Again, exponential and asymptotic stablility of the system requires $1 > \lvert z_2 \rvert \ge \lvert z_1 \rvert$ (the ordering labels $z_2$ as the maximum eigenvalue).
                <ol>
                  <li>Repeated, real roots: $\lvert z_1 \rvert = \lvert z_2 \rvert = \textcolor{Mahogany}{\tfrac{1+\beta_p}{2}} < 1$. This translates to $\beta_p < 1$, already satisfied by $\beta_p < \beta$.
                  </li>
                  <li>Distinct, real roots: $\lvert z_1 \rvert < \lvert z_2 \rvert = \textcolor{Mahogany}{\tfrac{1+\beta_p}{2} + \tfrac{\sqrt{D}}{2} } < 1$. This translates to $\gamma < 1$, already satisfied by $\gamma \le \beta$.
                  </li> 
                  <li>Distinct, complex-conjugate roots: $\lvert z_1 \rvert = \lvert z_2 \rvert \le  \textcolor{Mahogany}{\sqrt{\beta_p-k_p}} < 1$. Since $\alpha\,\eta\,\lambda < \beta$, then $\beta - \alpha\,\eta\,\lambda\,\gamma < 1$ translates to $\gamma \ge -\tfrac{(1-\beta)}{\beta}$.
                  </li>   
                </ol>
                $$\begin{equation}\label{eq:azero}
                \boxed{-\tfrac{(1-\beta)}{\beta} \le \gamma \le \beta}.
                \end{equation}
                $$
                <p>
                By eigenvalue decomposition of the system matrix in $\rxt = \rA^{t}\,\rxi$, and taking any consistent norm $\|\cdot\|$ of both sides, we obtain a certificate for both exponential, and asymptotic convergence in the mean as
                $$ \boxed{\| \rxt \| \le \tfrac{2}{1+\beta_p} \cdot |\textcolor{Mahogany}{z_2}|^{t}\, \|\rxi\|}.$$
  
                <!-- $$
                \begin{aligned}
                0 < \alpha < \tfrac{\beta}{\eta}\, \tfrac{1}{\lambda},\\
                -(1-\beta) < \gamma \le \beta,\\
                0 < \beta < 1.
                \end{aligned}
                $$ -->
                </p>
            </section>

            <section class="note">
              <h4 id="note-title-7">AutoSGM: Reflections </h4>
              <div class="teaser2">              
               <b>Recall</b>: Our holy grail is to get the error to converge to <strong>zero</strong> in at most two iterations. 
              </div>
              <p> Let $0 < c_1 < 1$, the system analysis leads to
                  $$
                  \boxed{
                    \begin{aligned}
                    0 < \beta < 1,\\
                    \gamma = -\tfrac{(1-\beta)}{\beta},\\
                    \alpha = c_1\,\tfrac{\beta}{\eta}\, \tfrac{1}{\lambda}.
                    \end{aligned}
                  }
                  $$
              We set $c_1 = 0.99 \approx 1$ to operate near the fastest convergence without instability. 
              <!-- Analyzing the mean-square error convergence, we will get that $\tfrac{2}{3} < c_1 < 1$. -->
              </p>

              <b>Play with the controls </b>
              <ol>
                <li>Click on the OPT button</li>
                <li>Ensure the Input selector reads Step </li>
                <li>Slide the $\beta$ controls, and observe the system.</li>
              </ol>
              
              <ol>
                <li>Click on the PHB button</li>
                <li>Ensure the Input selector reads Step </li>
                <li>Slide the $\beta$ controls, and observe the system.</li>
              </ol>
              <ol>
                <li>Repeat the above steps for the NAG button.</li>
                <li>Repeat the above steps for the MLS button.</li>
              </ol>
            
              <b>Observations </b> using the derived learning rate choice.
              <ol>
                <li> <b>Ours</b> $\gamma = -\tfrac{(1-\beta)}{\beta}$. <b>Design goal met </b> for any $0 < \beta < 1$.
                </li>
                <li> PHB: $\gamma = 0$. Fast convergence met for a wide range of $\beta$, but not for extremely lower values. Design goal met for only higher values of $\beta$.
                </li>                
                <li> NAG: $\gamma = \tfrac{\beta}{1+\beta}$. Fast convergence met for only higher values of $\beta > 0.5$. Design goal is not met.
                </li>
                <li> MLS: $\gamma = 1-\sqrt{2(1-\beta)}$. Fast convergence met for a wider range of $\beta$, but not for extremely lower and higher values. Design goal is not met.
                </li>
              </ol>


              <div class="teaser2">      
                <p>In this setup, published <em>optimal</em> parameter choices for PHB and NAG collapse to $\alpha=\tfrac{1}{\lambda}, \beta=\gamma=0$, which is just the plain method. <b> We saw this choice is not good enough</b>, merely using the inverse of the Hessian neither gets us close to stable nor accelerated learning.
                </p>       
                In sharp contrast to current momentum theory, <b>the picture changes with AutoSGM</b>. Our AutoSGM structure, exposes a closed-form parameterization of the learning algorithm that certifies exponential, asymptotic mean convergence, with the striking property that the error can be driven to zero in at most two iterations for any $0 < \beta < 1$. 
                <p>
                This highlights deeper themes in linear systems, signal processing and control theory. We believe this perspective, better motivates what has long been called <em>momentum</em> in accelerated learning applications, not as an heuristic but as a <b>precisely engineered dynamic system</b>.
                </p>
              </div>

            </section>
                                    
          </div>
        </div>
      
        <div class="note-controls">
          <button class="note-btn" id="prev">Back</button>
          <button class="note-btn" id="next" aria-label="Next note">Next</button>
        </div>
      </div>
      
    </div>

    <div class="item-lsidebar">
      <aside class="infoPanel" id="infoPanel">
        <h3><span class="cgreen">Auto</span>SGM: LTI System Info</h3>
        <dl class="sys-info">
          <dt>Pole (change-level)</dt>
          <dd class="cgreen">$ \beta_p = \beta - \eta \alpha \lambda$ = <span class="value" id="poleVal"></span>
          </dd>

          <dt>Gain (change-level)</dt>
          <dd >$ k_p=-\eta\alpha\lambda(1-γ) $ = <span class="value" id="ingainVal"></span></dd>

          <!-- <dt><span id="fstate">Lowpass</span> stable $\beta_p$-range</dt>
          <dd class="cgreen">$({\beta_p}_{\min}, {\beta_p}_{\max})$ = <span class="value" id="poleLimits"></span></dd> -->
      
          <dt> Stable $\alpha$-range</dt>
          <dd class="cgreen">$(\alpha_{\min}, \alpha_{\max})$ = <span class="value" id="alphaLimits"></span></dd>
        </dl>

        <div id="controls">
            <div class="slider-group">
              <label>$\beta$ <span id="betaVal">0.90</span></label>
              <input id="beta" type="range" min="0.001" max="0.99" step="0.001" value="0.9">
            </div>

            <div class="slider-group">
              <label>$\gamma$ <span id="gammaVal">0.00</span></label>
              <input id="gamma" type="range" min="-1" max="1" step="0.01" value="0.0">
            </div>

            <div class="slider-group">
              <label>$\lambda$ <span id="lamVal">1.00</span></label>
              <input id="eigval" type="range" min="0.01" max="100.0" step="0.01" value="1.0">
            </div>

            <div class="slider-group">
              <label>$\alpha$ <span id="alphaVal">0.50</span></label>
              <input id="alpha" type="range" min="0.0" max="1.0" step="0.001" value="0.1">
            </div>

            <div class="slider-group">
                <label>Input</label>
                <select id="inputType">
                  <option value="step">Step</option>
                  <option value="impulse">Impulse</option>
                </select>
            </div>    

            <div style="display:flex;gap:8px;align-items:center;">
              <button id="play" class="btn">Play</button>
              <button id="pause" class="btn" disabled>Pause</button>
              <button id="reset" class="btn">Reset</button>
              <span class="status" id="stability">Stable</span>
            </div>
            <div style="display:flex;gap:8px;align-items:center;">   
              <button id="PHB" class="btn btnalg">PHB</button>
              <button id="NAG" class="btn btnalg">NAG</button>
              <button id="SFUN" class="btn btnalg">MLS</button>
            </div>     
            <div style="display:flex;gap:8px;align-items:center;">  
              <button id="NOF" class="btn btnalg">RAW-M</button>   
              <button id="NOF2" class="btn btnalg">RAW-L</button>  
              <button id="OPT" class="btn btnalg">OPT</button>
              <button id="free" class="btn btnalg">Free Mode</button>
            </div>    
        </div>  
      </aside>
    </div>

    <div class="item-lplt" id="leftPlotc">      
    </div>


    <div class="rplt-top" id="rightPlotctop"> 
    </div> 
       
    <div class="rplt-btm" id="rightPlotcbottom">
    </div>   

    <div class="item-foot">
      <section class="foot-sec1">
      <h4>First-order LTI change-level and overall error dynamics. </h4>
      <ol class="foot-ol1"> 
      <li>First plot shows the <em>iteration-domain response</em> of the SGM's error $ε[t]$ from an optimum point and its change-level $\Delta\varepsilon[t]$.</li>
      <li>Second plot shows <em>two roots of the overall error behavior</em>.
      <li>Third plot shows <em>change-level pole position</em>.</li> 
      </ol>
      <span> Highlighted in the second and third plots are <span class="cgreen">stable</span>, possibly <span class="cred">oscillatory</span> and actual <span class="cred">unstable</span> (outside the unit-circle) locations.</span>
      </section>
      
    </div>

</div>

<!-- page content  -->
<script src="quad_sim.js"></script>

</body>
</html>
