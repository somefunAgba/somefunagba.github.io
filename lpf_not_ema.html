<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li > a, .site-nav > ul.nav-list:first-child > li > ul > li:not(:nth-child(4)) > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(1) > ul > li:nth-child(4) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(1) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(1) > ul > li:nth-child(4) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(1) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(1) > ul.nav-list > li.nav-list-item:nth-child(4) > ul.nav-list { display: block; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Momentum is not an EMA | Research Notes</title> <meta name="generator" content="Jekyll v4.4.1" /> <meta property="og:title" content="Momentum is not an EMA" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Lowpass filtering versus Mean estimation via EMAs How Gradient smoothing called Momentum is not an EMA" /> <meta property="og:description" content="Lowpass filtering versus Mean estimation via EMAs How Gradient smoothing called Momentum is not an EMA" /> <link rel="canonical" href="http://localhost:4000/lpf_not_ema" /> <meta property="og:url" content="http://localhost:4000/lpf_not_ema" /> <meta property="og:site_name" content="Research Notes" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Momentum is not an EMA" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Lowpass filtering versus Mean estimation via EMAs How Gradient smoothing called Momentum is not an EMA","headline":"Momentum is not an EMA","url":"http://localhost:4000/lpf_not_ema"}</script> <!-- End Jekyll SEO tag --> <script> window.MathJax = { tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], displayMath: [['$$', '$$'], ['\\[', '\\]']], processEscapes: true, tags: 'ams' // Enables equation numbering if you use \label{} and \ref{} }, options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] } }; </script> <!--Macros--> <div style="display: none"> $$ \newcommand{sca}[1]{\langle #1 \rangle} \newcommand{\scalong}[1]{(#1_1,\dots,#1_k)} \newcommand{\red}[1]{\textcolor{OrangeRed}{#1}} \newcommand{\blue}[1]{\textcolor{blue}{#1}} \newcommand{\green}[1]{\textcolor{OliveGreen}{#1}} \newcommand{\orange}[1]{\textcolor{orange}{#1}} \newcommand{\purple}[1]{\textcolor{purple}{#1}} \newcommand{\gray}[1]{\textcolor{gray}{#1}} \newcommand{\teal}[1]{\textcolor{teal}{#1}} \newcommand{\gold}[1]{\textcolor{gold}{#1}} \newcommand{\bluea}[1]{\textcolor{RoyalBlue}{#1}} \newcommand{\reda}[1]{\textcolor{Red}{#1}} \newcommand{\redb}[1]{\textcolor{RubineRed}{#1}} \newcommand{\greena}[1]{\textcolor{LimeGreen}{#1}} \newcommand{\golden}[1]{\textcolor{GoldenRod}{#1}} \newcommand{\filter}[1]{\green{#1}} \newcommand{\param}[1]{\purple{#1}} \newcommand{\state}[1]{\blue{#1}} \newcommand{\statex}[1]{\bluea{#1}} \newcommand{\stateu}[1]{\greena{#1}} \newcommand{\statez}[1]{\golden{#1}} \newcommand{\input}[1]{\gray{#1}} \newcommand{\gain}[1]{\red{#1}} \newcommand{\gainx}[1]{\reda{#1}} \newcommand{\trust}[1]{\teal{#1}} \newcommand{\schedule}[1]{\gold{#1}} $$ <!-- TROLRS --> $$ \newcommand{\trobjsca}{\mathcal{D}[t,i]} \newcommand{\trobjmat}{\mathcal{D}[t]} \newcommand{\Tr}{\mathrm{Tr}} \newcommand{\step}{\Delta[t+1, i] = -\alpha[t,i]\,\mathbf{g}[t,i]} \newcommand{\stepv}{\Delta[t+1, i] = -\alpha[t,i]\,\mathbf{v}[t,i]} \newcommand{\matstep}{\Delta[t+1] = -\alpha[t]\,\mathbf{g}[t]} \newcommand{\matstepv}{\Delta[t+1] = -\alpha[t]\,\mathbf{v}[t]} \newcommand{\ngrad}{\bar{\mathbf{g}}[t,i]} \newcommand{\ngradv}{\bar{\mathbf{v}}[t,i]} \newcommand{\ngradsq}{\bar{\mathbf{g}}^2[t,i]} \newcommand{\ngradvsq}{\bar{\mathbf{v}}^2[t,i]} \newcommand{\nmatgrad}{\bar{\mathbf{g}}[t]} \newcommand{\nmatgradv}{\bar{\mathbf{v}}[t]} \newcommand{\fof}{\mathbb{H}_{\beta,\,\gamma}} \newcommand{\expg}{\mathbb{E}\big[\mathbf{g}[t,i]\big]} \newcommand{\expv}{\mathbb{E}\big[\mathbf{v}[t,i]\big]} $$ $$ \newcommand{\stepmom}{\mathbb{E}\big[{\Delta}^2[t+1, i]\big]} \newcommand{\matstepmom}{\mathbb{E}\big[\Tr\big(\Delta^\intercal[t+1]\,\Delta[t+1]\big]} \newcommand{\gmatstepmom}{\mathbb{E}\big[\Tr\big(\left<{\Delta[t+1],\Delta[t+1]}\right>\big)\big]} $$ $$ \newcommand{\stepcorrng}{\mathbb{E}\big[\Delta[t+1, i]\,\ngrad\big]} \newcommand{\stepcorrngv}{\mathbb{E}\big[\Delta[t+1, i]\,\ngradv\big]} \newcommand{\matstepcorrng}{\mathbb{E}\big[\Tr\big(\Delta^\intercal[t+1]\,\nmatgrad \big) \big]} \newcommand{\matstepcorrngv}{\mathbb{E}\big[\Tr\big(\Delta^\intercal[t+1]\,\nmatgradv \big) \big]} \newcommand{\gmatstepcorrng}{\mathbb{E}\big[\Tr\big(\left\langle{\Delta[t+1],\nmatgrad}\right\rangle \big)\big]} \newcommand{\gmatstepcorrngv}{\mathbb{E}\big[\Tr\big(\left\langle{\Delta[t+1],\nmatgradv}\right\rangle \big)\big]} $$ $$ \newcommand{\stepcorru}{\mathbb{E}\big[\Delta[t+1, i]\,\mathbf{u}[t,i]\big]} \newcommand{\matstepcorru}{\mathbb{E}\big[\Delta^\intercal[t+1]\,\mathbf{u}[t]\big]} $$ $$ \newcommand{\numngradcorr}{\mathbb{E}\big[\ngradsq\big]} \newcommand{\numwgcorr}{\mathbb{E}\big[\mathbf{w}[t,i]\,\ngrad\big]} \newcommand{\numngradvcorr}{\mathbb{E}\big[\ngradvsq\big]} \newcommand{\numwvcorr}{\mathbb{E}\big[\mathbf{w}[t,i]\,\ngradv\big]} \newcommand{\dengmom}{\mathbb{E}\big[\mathbf{g}^2[t,i]\big]} \newcommand{\dengmomv}{\mathbb{E}\big[\mathbf{v}^2[t,i]\big]} \newcommand{\matdengmom}{\mathbb{E}\big[\mathbf{g}[t]\mathbf{g}^\intercal[t]\big]} \newcommand{\matdengmomv}{\mathbb{E}\big[\mathbf{v}[t]\mathbf{v}^\intercal[t]\big]} \newcommand{\dengmomsqrt}{\sqrt{\mathbb{E}\big[\mathbf{g}^2[t,i]\big]}} \newcommand{\matdengmomsqrt}{\mathbb{E}\big[\mathbf{g}[t]\mathbf{g}^\intercal[t]\big]^{\text{-}\frac{1}{2}}} \newcommand{\matdenvmomsqrt}{\mathbb{E}\big[\mathbf{v}[t]\mathbf{v}^\intercal[t]\big]^{\text{-}\frac{1}{2}}} \newcommand{\matngradcorr}{\mathbb{E}\big[\nmatgrad\nmatgrad^{\intercal}\big]} \newcommand{\matngradvcorr}{\mathbb{E}\big[\nmatgradv\nmatgradv^{\intercal}\big]} \newcommand{\matwngradcorr}{\mathbb{E}\big[\mathbf{w}[t]\nmatgrad^{\intercal}\big]} \newcommand{\matwngradvcorr}{\mathbb{E}\big[\mathbf{w}[t]\nmatgradv^{\intercal}\big]} $$ </div> <!-- Load Google Fonts --> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <!-- Copied from https://docs.mathjax.org/en/latest/web/components/combined.html --> <script type="text/javascript" id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"> </script> <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> </script> <!-- Automatically display code inside script tags with type=math/tex using MathJax --> <!-- <script type="text/javascript" defer src="/assets/js/mathjax-script-type.js"> </script> --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"><div class="site-branding"> <span class="site-title ">Research Notes</span> <span class="site-description">Signal processing, and control in learning and optimization.</span> </div> </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in AutoSGM: Unifying Momentum Methods category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/asgm.html" class="nav-list-link">AutoSGM: Unifying Momentum Methods</a><ul class="nav-list"><li class="nav-list-item"><a href="/learning_dynamics" class="nav-list-link">Smooth Learning Dynamics</a></li><li class="nav-list-item"><a href="/asgm_trolrs" class="nav-list-link">Trust-region Optimal Learning rates</a></li><li class="nav-list-item"><a href="/asgm_cjg" class="nav-list-link">Conjugated Directions</a></li><li class="nav-list-item"><a href="/lpf_not_ema" class="nav-list-link">Momentum is not an EMA</a></li><li class="nav-list-item"><a href="/asgm_lrwinds" class="nav-list-link">Learning-Rate Annealing</a></li></ul></li><li class="nav-list-item"><a href="/about" class="nav-list-link">About Me</a></li></ul> </nav> <footer class="site-footer"> © 2026. <a href="/about">Oluwasegun Somefun</a> </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Research Notes" aria-label="Search Research Notes" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/asgm.html">AutoSGM: Unifying Momentum Methods</a></li> <li class="breadcrumb-nav-list-item"><span>Momentum is not an EMA</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 class="fs-9" id="lowpass-filtering-versus-mean-estimation-via-emas"> <a href="#lowpass-filtering-versus-mean-estimation-via-emas" class="anchor-heading" aria-labelledby="lowpass-filtering-versus-mean-estimation-via-emas"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Lowpass filtering versus Mean estimation via EMAs </h1> <p class="fs-6 fw-300">How Gradient smoothing called Momentum is not an EMA</p> <blockquote> <p><em>Oluwasegun Somefun</em>. “<a href="https://somefunagba.github.io/lpf_not_ema.html">Momentum is not an EMA</a>.” <em>AutoSGM Framework</em>, 2025.</p> </blockquote> <blockquote> <p><strong>Please cite this page</strong> if you use information from these notes for your work, research, or anything that requires academic or formal citation.</p> </blockquote><hr /> <details> <summary class="text-delta"> Table of contents </summary> <ol id="markdown-toc"> <li><a href="#lowpass-filtering-versus-mean-estimation-via-emas" id="markdown-toc-lowpass-filtering-versus-mean-estimation-via-emas">Lowpass filtering versus Mean estimation via EMAs</a> <ol> <li><a href="#the-singlepole-lowpass-filter" id="markdown-toc-the-singlepole-lowpass-filter">The Single‑Pole Low‑Pass Filter</a></li> <li><a href="#ema-vs-typical-lowpass-filtering-regimes" id="markdown-toc-ema-vs-typical-lowpass-filtering-regimes">EMA vs. Typical Lowpass filtering Regimes</a> <ol> <li><a href="#frequencydomain-representation" id="markdown-toc-frequencydomain-representation">Frequency‑Domain Representation</a></li> <li><a href="#takeaways" id="markdown-toc-takeaways">Takeaways</a></li> </ol> </li> </ol> </li> </ol> </details><hr /> <p>It is tempting to conflate the typical <em>lowpass filtering</em> operation of smoothing gradients, commonly called <em>momentum</em> with an <em>exponential moving average (EMA)</em> of gradients, since both involve recursive exponential smoothing.</p> <p>However, the two mechanisms are fundamentally different <strong>modes of the same first-order filter</strong>. Thinking in signal‑processing terms makes the distinction clear.</p> <blockquote> <p>An EMA is just an operating point in the single-pole lowpass filter (\(\beta \approx 1, \gamma=0\))</p> </blockquote> \[H(z) = \eta\,\frac{1 - \gamma z^{-1}}{1 - \beta z^{-1}},\]<hr /> <h2 id="the-singlepole-lowpass-filter"> <a href="#the-singlepole-lowpass-filter" class="anchor-heading" aria-labelledby="the-singlepole-lowpass-filter"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Single‑Pole Low‑Pass Filter </h2> <p>Consider a first-order filter with no zero, \(\gamma=0\), only a single pole \(\beta\). The filter reduces to a single‑pole IIR (infinite impulse recursive) filter recursion:</p> \[x_{t+1} = \beta x_t + (1-\beta) u_t,\] <p>where \(u_t\) is the input and \(x_t\) is the filtered output.</p> <ul> <li> <p>This is a <strong>causal linear filter</strong> with impulse response<br /> \(h[t] = (1-\beta)\beta^t, \quad t \geq 0,\) i.e. an exponentially decaying weighting of past inputs.</p> </li> <li> <p>The update direction is therefore the <strong>cumulative contribution of past inputs</strong>, exponentially weighted by \(\lvert \beta \rvert &lt; 1\).</p> </li> </ul><hr /> <h2 id="ema-vs-typical-lowpass-filtering-regimes"> <a href="#ema-vs-typical-lowpass-filtering-regimes" class="anchor-heading" aria-labelledby="ema-vs-typical-lowpass-filtering-regimes"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> EMA vs. Typical Lowpass filtering Regimes </h2> <ul> <li> <p><strong>EMA regime:</strong><br /> The output behaves like a <em>long time‑average statistic</em> only if<br /> \(0.9 \ll \beta &lt; 1\) and \(\gamma=0.\)<br /> In this high \(\beta\) regime (<strong>extreme smoothing</strong>), the filter is said to have a long-time memory, a larger time-lag, and functions to approximate statistical expectations by mostly assuming ergodicity of the input to the filter. <strong>This is why in practice, even when ergodic assumptions do not hold, values like \(0.99, 0.999, 0.9999\) are effective</strong>.<br /> The output behaves like a <em>shorter time‑average statistic</em> if \(0 &lt; \beta \le 0.9\) (<strong>normal smoothing</strong>), and so the filter is an extremely poor estimator of expectation under ergodicity, but possess faster tracking behavior with respect to the input signal, due to shorter time-lag.</p> </li> <li> <p><strong>Typical Lowpass filtering regime:</strong><br /> In this regime, we are not interested in estimating expected values, but merely reducing the high-frequency noise content in a signal. It is simply returning its <strong>low‑pass filtered version</strong> of the input. This is the typical momentum. Since we want smoothing, \(0 &lt; \beta \le 0.9\) (<strong>normal smoothing</strong>), <strong>using \(0.9\) has long been used (before deep learning) as a good default value, when nothing is known about the frequency characteristics of the input signal</strong>.</p> </li> </ul><hr /> <h4 id="frequencydomain-representation"> <a href="#frequencydomain-representation" class="anchor-heading" aria-labelledby="frequencydomain-representation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Frequency‑Domain Representation </h4> <p>The transfer function of the single pole filter is</p> \[H(z) = (1-\beta)\,\frac{1}{1 - \beta z^{-1}},\] <p>on the unit circle \(z = e^{j\omega}\).</p> <ul> <li> <p><strong>Magnitude response:</strong><br /> Low frequencies (\(\omega\) nearer to \(0\)) pass with gain near 1.<br /> Both lower and higher frequencies are attenuated more strongly as \(\beta \to 1\).<br /> With high \(\beta\) acts as a <em>very narrow-band low‑pass filter</em>, and thus an EMA.</p> </li> <li> <p><strong>Phase response:</strong><br /> The filter introduces a delay (phase lag) that grows with \(\beta\).</p> </li> </ul><hr /> <h4 id="takeaways"> <a href="#takeaways" class="anchor-heading" aria-labelledby="takeaways"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Takeaways </h4> <p>A single-pole lowpass filter’s <strong>interpretation</strong> as an EMA (short-term or long-term) <strong>depends on its pole location</strong> (the value of \(\beta\)) and the intent behind its use:</p> <ul> <li><strong>High \(\beta\) regime:</strong><br /> The pole of the filter is very close to the unit circle (edge of stability often called <strong>marginal stability</strong>). <ul> <li>The filter has <strong>long memory</strong> and effectively integrates over a large window of past inputs.</li> <li>This makes the output track only the <strong>slowly‑varying mean</strong> of the input (under ergodic assumptions).</li> <li>High‑frequency content (rapid changes, oscillations, transient spikes) is heavily attenuated, i.e. <strong>a lot of information is lost</strong>.</li> <li>In estimation, this is the EMA regime: the output is treated as a proxy for a statistical expectation.</li> </ul> </li> <li><strong>Low–Moderate \(\beta\) regime:</strong><br /> The pole is further inside the unit circle. <ul> <li>The filter has <strong>shorter memory</strong> and responds more directly to the current input.</li> <li>The output is a <strong>smoothed version of the full input signal</strong>, not its mean estimate (under ergodic assumptions).</li> <li>High‑frequency noise is reduced, <strong>but the underlying variations are still preserved</strong>.</li> <li>In stochastic gradient learning, this is the <strong>momentum regime</strong>: the filter smooths and shapes the input trajectory rather than estimating a mean value. We call this <strong>lowpass regularization</strong>.</li> </ul> </li> </ul> <p><strong>Momentum is not an EMA</strong>. Conflating the two misses the point: it is the <em>same lowpass filter operating in a different regime</em>, with different intent <strong>lowpass smoothing vs. mean estimation</strong>.</p> <p><strong>EMA operations</strong> are achieved via a <strong>single-pole lowpass filter</strong>. But <strong>typical smoothing operations</strong> can be achieved using simple to more-complicated filter configurations.</p> <!-- We acknowledge that CIFAR‑10 and GPT‑2 are established benchmarks. However, they remain widely used in optimizer research through 2025 (Wu, 2025; Keller, 2025; Vasilev, 2025), precisely because they provide reproducible baselines and allow controlled evaluation of optimizer behavior. Our focus is on theoretical contributions, which are model‑agnostic, and these benchmarks serve as illustrative testbeds rather than claims of state‑of‑the‑art performance. Powerful Design of Small Vision Transformer on CIFAR‑10 Investigating CNNs Performance on the CIFAR‑10 Dataset through Hyperparameter Tuning CIFAR‑10 AIRBench Performance Benchmarks Benchmarking CIFAR‑10 with Tsetlin Machines A Second‑Order‑Like Optimizer with Adaptive Gradient Scaling 94% on CIFAR‑10 in 3.29 Seconds on a Single GPU CIFAR‑10: Still a standard for testing optimizer variations because it’s lightweight, reproducible, and allows rapid ablation studies. Many optimizer papers in 2023–2024 (e.g., new SGD variants, adaptive methods) reported CIFAR‑10 results alongside larger datasets like ImageNet. GPT‑2: Remained a common NLP benchmark for optimizer studies because training GPT‑3/4‑scale models is prohibitively expensive. Researchers used GPT‑2 small/medium as a reproducible proxy to study optimizer dynamics in transformers. Papers in 2024 still benchmarked optimizers on GPT‑2 to demonstrate transferability to language modeling tasks. --> </main> <hr> <footer> <p><a href="#top" id="back-to-top">Back to top</a></p> <div class="d-flex mt-2"> </div> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
